{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkMN55KRzCxB"
      },
      "source": [
        "# **1) Install tensorflow 1.x**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKiu6MPl1Xi9"
      },
      "outputs": [],
      "source": [
        "!pip uninstall tensorflow-gpu\n",
        "!pip install tensorflow==1.15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uOXZ3Ojn0rD"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCy2W4baNZL-"
      },
      "outputs": [],
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjfRnVN12JWF"
      },
      "source": [
        "# **2) Import dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwoREwF6Jxdy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92GABWQa1eYT"
      },
      "source": [
        "# **3) Create *`customTF1`*,  and inside *`training`* and *`data`* folders in google drive**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca4Hv2sT4lt-"
      },
      "source": [
        "# **4) Create and upload your image files and txt files.**\n",
        " Create a folder named ***images*** for your custom dataset images and create another folder named ***annotations*** for its corresponding xml files.\n",
        " \n",
        " Next, create their zip files and upload them to the ***customTF1*** folder in your drive.\n",
        "\n",
        "\n",
        "\n",
        " **<ins>NOTE</ins>**: Make sure all the image files have extension as \".jpg\" only.\n",
        " Other formats like \".png\" , \".jpeg\" or even \".JPG\" will give errors since the generate_tfrecord and xml_to_csv scripts here have only \".jpg\" in them\n",
        "\n",
        "Annotations should be in PASCAL_VOC XML formats!\n",
        "\n",
        "Upload the *`generate_tfrecord.py`* file to the *`customTF1`* folder on your drive.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLsPGJiuxRrK"
      },
      "source": [
        "#**5) Mount drive and link your folder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhZoiRBoqnju"
      },
      "outputs": [],
      "source": [
        "#mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# this creates a symbolic link so that now the path /content/gdrive/My\\ Drive/ is equal to /mydrive\n",
        "!ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
        "\n",
        "#list contents in your drive\n",
        "!ls /mydrive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tWHcoAF9f6K"
      },
      "source": [
        "# **6) Clone the TensorFlow models git repo & Install TensorFlow Object Detection API**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iv3C8-s0koQU"
      },
      "outputs": [],
      "source": [
        "# clone the tensorflow models on the colab cloud vm\n",
        "!git clone --q https://github.com/tensorflow/models.git\n",
        "\n",
        "#navigate to /models/research folder to compile protos\n",
        "%cd models/research\n",
        "\n",
        "# Compile protos.\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "# Install TensorFlow Object Detection API.\n",
        "!cp object_detection/packages/tf1/setup.py .  \n",
        "!python -m pip install .\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D1UNW7c9O-I"
      },
      "source": [
        "# **7) Test the model builder**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "St1r_0-w9jqI"
      },
      "outputs": [],
      "source": [
        "# testing the model builder\n",
        "!python object_detection/builders/model_builder_tf1_test.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrNF9Lnw_m7O"
      },
      "source": [
        "# **8) Navigate to *`/mydrive/customTF1/data/`* and unzip the *`images.zip`* and *`annotations.zip`* files into the *`data`* folder**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5C1j-Akbdepl"
      },
      "outputs": [],
      "source": [
        "!cd /mydrive/customTF1/data/ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYUW7UZejKFb"
      },
      "source": [
        "# **9) Create `test_labels` & `train_labels`**\n",
        "Current working directory is /mydrive/customTF1/data/\n",
        "\n",
        "Divide annotations into test_labels(20%) and train_labels(80%)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AoyMt_vssl1j"
      },
      "outputs": [],
      "source": [
        "#creating two dir for training and testing\n",
        "!mkdir test_labels train_labels\n",
        "\n",
        "# lists the files inside 'annotations' in a random order (not really random, by their hash value instead)\n",
        "# Moves the first 274/1370 labels (20% of the labels) to the testing dir: `test_labels`\n",
        "!ls annotations | sort -R | head -12 | xargs -I{} mv {} test_labels/\n",
        "\n",
        "\n",
        "# Moves the rest of the labels ( 1096 labels ) to the training dir: `train_labels`\n",
        "!ls annotations | xargs -I{} mv {} train_labels/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH67M2M12s3n"
      },
      "source": [
        "# **10) Create the CSV files and the \"label_map.pbtxt\" file**\n",
        "Current working directory is /mydrive/customTF1/data/\n",
        "\n",
        "Run xml_to_csv script below to create ***test_labels.csv*** and ***train_labels.csv***\n",
        "\n",
        "This also creates the ***label_map.pbtxt*** file using the classes mentioned in the xml files. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58q6NAscpu59"
      },
      "outputs": [],
      "source": [
        "!cd /mydrive/customTF1/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyGisGxK4ag0"
      },
      "outputs": [],
      "source": [
        "#adjusted from: https://github.com/datitran/raccoon_dataset\n",
        "def xml_to_csv(path):\n",
        "  classes_names = []\n",
        "  xml_list = []\n",
        "\n",
        "  for xml_file in glob.glob(path + '/*.txt'):\n",
        "    f = open(xml_file, \"r\")\n",
        "    a = f.read().split( )\n",
        "    if (\"train_labels\" in path):\n",
        "      k = xml_file.replace(\"/mydrive/customTF1/data/train_labels/\", \"\")\n",
        "    else:\n",
        "      k = xml_file.replace(\"/mydrive/customTF1/data/test_labels/\", \"\")\n",
        "    print(k)\n",
        "    value = (k.replace(\".txt\", \".png\"),\n",
        "                     480,\n",
        "                     360,\n",
        "                     \"Ear\",\n",
        "                     int(a[1]),\n",
        "                     int(a[2]),\n",
        "                     int(a[3]),\n",
        "                     int(a[4]))\n",
        "    xml_list.append(value)\n",
        "  column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "  xml_df = pd.DataFrame(xml_list, columns=column_name) \n",
        "  classes_names = list(set(classes_names))\n",
        "  classes_names.sort()\n",
        "  return xml_df, classes_names\n",
        "\n",
        "for label_path in ['train_labels', 'test_labels']:\n",
        "  image_path = os.path.join('/mydrive/customTF1/data/' + label_path)\n",
        "  xml_df, classes = xml_to_csv(image_path)\n",
        "  xml_df.to_csv(f'/mydrive/customTF1/data/{label_path}.csv', index=None)\n",
        "  print(f'Successfully converted {label_path} xml to csv.')\n",
        "\n",
        "label_map_path = os.path.join('/mydrive/customTF1/data/' + \"label_map.pbtxt\")\n",
        "pbtxt_content = \"\"\n",
        "\n",
        "for i, class_name in enumerate(classes):\n",
        "    pbtxt_content = (\n",
        "        pbtxt_content\n",
        "        + \"item {{\\n    id: {0}\\n    name: '{1}'\\n}}\\n\\n\".format(i + 1, class_name)\n",
        "    )\n",
        "pbtxt_content = pbtxt_content.strip()\n",
        "with open(label_map_path, \"w\") as f:\n",
        "    f.write(pbtxt_content)\n",
        "    print('Successfully created label_map.pbtxt ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tblFU-i495qr"
      },
      "source": [
        "# **11) Create `train.record` & `test.record` files**\n",
        "\n",
        "Current working directory is /mydrive/customTF1/data/\n",
        "\n",
        "Run the *generate_tfrecord.py* script to create *train.record* and *test.record* files\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OH02x-8qzdp"
      },
      "outputs": [],
      "source": [
        "%cd /mydrive/customTF1/data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHGo0lCflP4P"
      },
      "outputs": [],
      "source": [
        "!python /mydrive/customTF1/generate_tfrecord.py train_labels.csv  label_map.pbtxt images/ train.record\n",
        "\n",
        "!python /mydrive/customTF1/generate_tfrecord.py test_labels.csv  label_map.pbtxt images/ test.record"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwWh49ClaBeD"
      },
      "source": [
        "# **12) Download pre-trained model checkpoint** \n",
        "\n",
        "Current working directory is /mydrive/customTF1/data/\n",
        "\n",
        "Download **ssd_mobilenet_v2_coco_2018_03_29.tar.gz** into the ***data*** folder & unzip it.\n",
        "\n",
        "A list of detection checkpoints for tensorflow 1.x can be found [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1_detection_zoo.md).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obEW7RNEcowc"
      },
      "outputs": [],
      "source": [
        "#Download the pre-trained model ssd_mobilenet_v2_coco_2018_03_29.tar.gz into the data folder & unzip it.\n",
        "\n",
        "!wget http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz\n",
        "!tar -xzvf ssd_mobilenet_v2_coco_2018_03_29.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XS-xqg02X9Ro"
      },
      "source": [
        "# **13) Get the model pipeline `config` file, make changes to it and put it inside the *`data`* folder**\n",
        "\n",
        "Edit the config file from ***/content/models/research/object_detection/samples/configs/*** in colab and copy the edited config file to the ***/mydrive/customTF1/data*** folder.\n",
        "\n",
        "\n",
        "**You need to make the following changes:**\n",
        "*   change ***num_classes*** to number of your classes.\n",
        "*   change ***test.record*** path, ***train.record*** path & ***labelmap*** path to the paths where you have created these files (paths should be relative to your current working directory while training).\n",
        "* change ***fine_tune_checkpoint*** to the path where the downloaded checkpoint from step 13 is. \n",
        "* change ***fine_tune_checkpoint_type*** with value **classification** or **detection** depending on the type.\n",
        "* change ***batch_size*** to any multiple of 8 depending upon the capability of your GPU.\n",
        "(eg:- 24,128,...,512).Mine is set to 24. \n",
        "* change ***num_steps*** to number of steps you want the detector to train. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_X2qpYuatgH"
      },
      "outputs": [],
      "source": [
        "#FOR METHOD 2 ,copy the confif file to the data folder \n",
        "!cp /content/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config /mydrive/customTF1/data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88pz7JpMNRRK"
      },
      "source": [
        "# **14) Load Tensorboard**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-86d0AXNQp7"
      },
      "outputs": [],
      "source": [
        "#load tensorboard\n",
        "%load_ext tensorboard \n",
        "%tensorboard --logdir '/content/gdrive/MyDrive/customTF1/training'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlzGrIfdAKj9"
      },
      "source": [
        "## **15) Train the model**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phPW9zD0fx2k"
      },
      "outputs": [],
      "source": [
        "#FOR METHOD 2 ,change directory to object_detection\n",
        "#%cd /content/gdrive/My Drive/customTF1/data/models/research/models/research/object_detection\n",
        "%cd /content/models/research/object_detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBr8MVa00Et-"
      },
      "source": [
        "## Training & evaluation using model_main.py\n",
        "\n",
        "```\n",
        "Run this command from the object_detection directory\n",
        "\n",
        "PIPELINE_CONFIG_PATH={path to pipeline config file}\n",
        "MODEL_DIR={path to model directory}\n",
        "NUM_TRAIN_STEPS=50000\n",
        "SAMPLE_1_OF_N_EVAL_EXAMPLES=1\n",
        "\n",
        "!python model_main.py --pipeline_config_path=${PIPELINE_CONFIG_PATH} --model_dir=${MODEL_DIR} --num_train_steps=${NUM_TRAIN_STEPS} --sample_1_of_n_eval_examples=${SAMPLE_1_OF_N_EVAL_EXAMPLES} --alsologtostderr\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "where **{PIPELINE_CONFIG_PATH}** points to the pipeline config and \n",
        "**{MODEL_DIR}** points to the directory in which training checkpoints and events will be written. Note that this binary will interleave both training and evaluation.\n",
        "\n",
        "**NOTE**: For best results, you should stop the training when the loss is less than 1 if possible, else train the model until the loss does not show any significant change for a while. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LS0SBCgRuox"
      },
      "outputs": [],
      "source": [
        "#For Training and Evaluation\n",
        "\n",
        "!python model_main.py --pipeline_config_path=/mydrive/customTF1/data/ssd_mobilenet_v2_coco.config --model_dir=/mydrive/customTF1/training --alsologtostderr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4esHYbk_DIj_"
      },
      "source": [
        "## RETRAINING THE MODEL ( in case you get disconnected )\n",
        "\n",
        "\n",
        "If you get disconnected or lose your session on colab vm, you can start your training where you left off as the checkpoint is saved on your drive inside the ***training*** folder. \n",
        "\n",
        " We just need to make one change in our pipeline config file.\n",
        "\n",
        "Change **fine_tune_checkpoint** to where your latest trained checkpoints have been written.\n",
        "``` \n",
        "fine_tune_checkpoint: \"/mydrive/customTF1/training/model.ckpt-xxxx\" (where model.ckpt-xxxx is the latest checkpoint)\n",
        "\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8k0kSTRUaI0U"
      },
      "source": [
        "## AUTO-CLICK TO AVOID BEING KICKED OFF COLAB\n",
        "\n",
        "Press (Ctrl + Shift + i) . Go to console. Paste the following code and press Enter.\n",
        "\n",
        "```\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\"); \n",
        "document\n",
        "  .querySelector('#top-toolbar > colab-connect-button')\n",
        "  .shadowRoot.querySelector('#connect')\n",
        "  .click() \n",
        "}\n",
        "setInterval(ClickConnect,60000)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nxn-FtdtpsTx"
      },
      "source": [
        "# **16) Test your trained model**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSIhCh_JQCH_"
      },
      "source": [
        "## Export inference graph\n",
        "\n",
        "Current working directory is /content/models/research/object_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NB4JHHqHSoiq"
      },
      "outputs": [],
      "source": [
        "!python export_inference_graph.py --input_type image_tensor --pipeline_config_path /mydrive/customTF1/data/ssd_mobilenet_v2_coco.config --trained_checkpoint_prefix /mydrive/customTF1/training/model.ckpt-16323 --output_directory /mydrive/customTF1/data/inference_graph2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEKLk34HBEF5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWVAC_eZxauD"
      },
      "source": [
        "## Test your trained Object Detection model on images\n",
        "\n",
        "Current working directory is /content/models/research/object_detection\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXPqUleBLtwm",
        "outputId": "4c43d1ef-8a27-4d93-9ab0-c812452e5058"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/models/research/object_detection'\n",
            "/content/gdrive/My Drive/customTF1/data\n"
          ]
        }
      ],
      "source": [
        "#navigate to object_detection folder\n",
        "%cd /content/models/research/object_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MqMGnynT5G3"
      },
      "outputs": [],
      "source": [
        "# Different font-type and font-size for labels text.(This step is optional)\n",
        "!wget https://freefontsdownload.net/download/160187/arial.zip\n",
        "!unzip arial.zip -d .\n",
        "\n",
        "%cd utils/\n",
        "!sed -i \"s/font = ImageFont.truetype('arial.ttf', 24)/font = ImageFont.truetype('arial.ttf', 50)/\" visualization_utils.py\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjeojItTPuXv"
      },
      "outputs": [],
      "source": [
        "# RUNNING INFERENCE\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "from google.colab.patches import cv2_imshow\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "import matplotlib\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "# This is needed to display the images.\n",
        "%matplotlib inline\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "# Change these values for the model used\n",
        "num_classes = 2 # Change this value to the number of classes of the model\n",
        "IMAGE_SIZE = (12, 8) # Output display size as you want\n",
        "\n",
        "# Use images in test dir\n",
        "IMAGE_DIR = \"/mydrive/mask_test_images\"\n",
        "IMAGE_PATHS = []\n",
        "for file in os.listdir(IMAGE_DIR):\n",
        "    if file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
        "        IMAGE_PATHS.append(os.path.join(IMAGE_DIR, file))\n",
        "\n",
        "# Set paths to the trained model\n",
        "PATH_TO_LABELS = '/content/gdrive/MyDrive/customTF1/data/label_map.pbtxt'\n",
        "PATH_TO_CKPT = os.path.join(os.path.abspath(\"/content/gdrive/MyDrive/customTF1/data/inference_graph\"), \"frozen_inference_graph.pb\")\n",
        "\n",
        "\n",
        "# Set tensorflow graph\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.GraphDef()\n",
        "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "# Set categories\n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map, max_num_classes=num_classes, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "# Convert input image to a numpy array\n",
        "def load_image_to_numpy(image):\n",
        "    (im_width, im_height) = image.size\n",
        "    return np.array(image.getdata()).reshape(\n",
        "        (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "# Inference pipeline\n",
        "def run_inference(image, graph):\n",
        "    with graph.as_default():\n",
        "        with tf.Session() as sess:\n",
        "            # Get handles to input and output tensors\n",
        "            ops = tf.get_default_graph().get_operations()\n",
        "            all_tensor_names = {\n",
        "                output.name for op in ops for output in op.outputs}\n",
        "            tensor_dict = {}\n",
        "            for key in [\n",
        "                'num_detections', 'detection_boxes', 'detection_scores',\n",
        "                'detection_classes', 'detection_masks'\n",
        "            ]:\n",
        "                tensor_name = key + ':0'\n",
        "                if tensor_name in all_tensor_names:\n",
        "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "                        tensor_name)\n",
        "            if 'detection_masks' in tensor_dict:\n",
        "                # The following processing is only for single image\n",
        "                detection_boxes = tf.squeeze(\n",
        "                    tensor_dict['detection_boxes'], [0])\n",
        "                detection_masks = tf.squeeze(\n",
        "                    tensor_dict['detection_masks'], [0])\n",
        "                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "                real_num_detection = tf.cast(\n",
        "                    tensor_dict['num_detections'][0], tf.int32)\n",
        "                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n",
        "                                           real_num_detection, -1])\n",
        "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n",
        "                                           real_num_detection, -1, -1])\n",
        "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "                detection_masks_reframed = tf.cast(\n",
        "                    tf.greater(detection_masks_reframed, .5), tf.uint8)\n",
        "                # Follow the convention by adding back the batch dimension\n",
        "                tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "                    detection_masks_reframed, 0)\n",
        "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "            # Run inference\n",
        "            output_dict = sess.run(tensor_dict,\n",
        "                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "            # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "            output_dict['num_detections'] = int(\n",
        "                output_dict['num_detections'][0])\n",
        "            output_dict['detection_classes'] = output_dict[\n",
        "                'detection_classes'][0].astype(np.uint8)\n",
        "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "            if 'detection_masks' in output_dict:\n",
        "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "    return output_dict\n",
        "\n",
        "# Run the inference for each image\n",
        "for image_path in IMAGE_PATHS:\n",
        "    image = Image.open(image_path)\n",
        "    # Conver the image to numpy array\n",
        "    image_np = load_image_to_numpy(image)\n",
        "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    # Perform the interence\n",
        "    output_dict = run_inference(image_np, detection_graph)\n",
        "    print(output_dict)\n",
        "    # Visualize\n",
        "    \"\"\"\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np,\n",
        "        output_dict['detection_boxes'],\n",
        "        output_dict['detection_classes'],\n",
        "        output_dict['detection_scores'],\n",
        "        category_index,\n",
        "        instance_masks=output_dict.get('detection_masks'),\n",
        "        use_normalized_coordinates=True,\n",
        "        line_thickness=20,\n",
        "        min_score_thresh=0.1)\n",
        "    plt.figure(figsize=IMAGE_SIZE, dpi=200)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(image_np)\n",
        "    \"\"\"\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "TF1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}